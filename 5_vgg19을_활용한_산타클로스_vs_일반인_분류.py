# -*- coding: utf-8 -*-
"""5. VGG19을 활용한 산타클로스 vs 일반인 분류.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RLTfuP71eujHgqWGog5Kz2M7ShUtI2ea
"""

import os
import glob
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.models as models
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from torchvision.datasets import ImageFolder
from PIL import Image

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

def display_images(image_paths, title, max_images=4):
    plt.figure(figsize=(12, 3))
    for i, image_path in enumerate(image_paths[:max_images]):
        img = plt.imread(image_path)
        plt.subplot(1, max_images, i+1)
        plt.imshow(img)
        plt.title(title)
        plt.axis('off')
    plt.show()

data_root = '/content/drive/MyDrive/컴퓨터비전_시즌2/5. 컴퓨터 비전/Data/5'

categories = ['Train Santa', 'Train Normal', 'Val Santa', 'Val Normal', 'Test Santa', 'Test Normal']

for category in categories:
    image_paths = glob.glob(f'{data_root}/{category.lower().replace(" ", "/")}/*')
    # print(image_paths)
    display_images(image_paths, category)
    print(f'{category} 총 이미지 수: {len(image_paths)}')

plt.figure(figsize=(10, 6))
plt.bar(categories, [len(glob.glob(f'{data_root}/{category.lower().replace(" ", "/")}/*')) for category in categories], color=['blue', 'orange', 'green', 'red'])
plt.title('Number of Images per Category')
plt.xlabel('Category')
plt.ylabel('Number of Images')
plt.xticks(rotation=45)
plt.show()

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomRotation(30),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.485, 0.406], std=[0.229, 0.224, 0.225])
])

# 영상, 라벨 데이터셋
train_dataset = ImageFolder(f'{data_root}/train/', transform=transform)
val_dataset = ImageFolder(f'{data_root}/val/', transform=transform)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

"""<img src='https://miro.medium.com/v2/resize:fit:1192/1*Q_bg1E3trWcjdk9_jnVGwg.png'>"""

class VGG19(nn.Module):
  def __init__(self, num_classes=1000):
    super(VGG19, self).__init__()
    self.features = nn.Sequential(
        nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),
        # inplace: 메모리 절약, 입력 텐서의 원본 데이터 변경
        nn.ReLU(inplace=True),
        nn.Conv2d(64, 64, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.MaxPool2d(kernel_size=2, stride=2),

        nn.Conv2d(64, 128, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv2d(128, 128, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.MaxPool2d(kernel_size=2, stride=2),

        nn.Conv2d(128, 256, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv2d(256, 256, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv2d(256, 256, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv2d(256, 256, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.MaxPool2d(kernel_size=2, stride=2),

        nn.Conv2d(256, 512, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv2d(512, 512, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv2d(512, 512, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv2d(512, 512, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.MaxPool2d(kernel_size=2, stride=2),

        nn.Conv2d(512, 512, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv2d(512, 512, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv2d(512, 512, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv2d(512, 512, kernel_size=3, padding=1),
        nn.ReLU(inplace=True),
        nn.MaxPool2d(kernel_size=2, stride=2)
        )


    self.classifier = nn.Sequential(
        nn.Linear(512 * 7 * 7, 4096),
        nn.ReLU(inplace=True),
        nn.Dropout(),
        nn.Linear(4096, 4096),
        nn.ReLU(inplace=True),
        nn.Dropout(),
        nn.Linear(4096, num_classes)
    )

  def forward(self, x):
    x = self.features(x)
    x = torch.flatten(x, 1)
    x = self.classifier(x)
    return x

# 사전 학습된 VGG19 모델 불러오기
pretrained_vgg19 = models.vgg19(pretrained=True)

model = VGG19(num_classes=1000)
model = model.to(device)

# 사전 학습된 모델의 features 부분에서 가중치 추출
pretrained_keys = set(pretrained_vgg19.features.state_dict().keys())

# state_dict 키와 모델의 파라미터 이름이 일치하지 않으면 오류가 발생
# strict=False 설정하면 일부 파라미터가 다르더라도 일치하는 부분만 로드, 나머지는 무시
result = model.features.load_state_dict(pretrained_vgg19.features.state_dict(), strict=False)

# 복사 후 커스텀 모델의 features 부분에서 가중치 추출
custom_keys = set(model.features.state_dict().keys())

# 커스텀 모델과 사전 락습된 모델 모두에 존재하는 가중치
successfully_copied__keys = pretrained_keys.intersection(custom_keys)

# 커스텀 모델에는 있지만 사전 학습된 모델에 없는 가중치
missing_keys = custom_keys - pretrained_keys

# 사전 학습된 모델에는 있지만 커스텀 모델에 없는 가중치
unexpected_keys = pretrained_keys - custom_keys

print('successfully_copied_keys: ', successfully_copied__keys)
print('missing_keys: ', missing_keys)
print('unexpected_keys: ', unexpected_keys)

for param in model.parameters():
  param.requires_grad = False

model

model.classifier[6] = nn.Linear(4096, 1) # 하나로 내보내기

for param in model.classifier.parameters():
  param.requires_grad = True

model = model.to(device)
model

loss_func = nn.BCEWithLogitsLoss()

def validate_model(model, val_loader, loss_func):
  model.eval()
  val_loss = 0.0
  correct = 0
  total = 0
  with torch.no_grad():
    for inputs, labels in val_loader:
      inputs, labels = inputs.to(device), labels.to(device)
      labels = labels.float().unsqueeze(1)
      outputs = model(inputs)
      val_loss += loss_func(outputs, labels).item()
      predicted = torch.sigmoid(outputs) > 0.5 # 0.5보다 크면 1 작으면 0
      total += labels.size(0)
      correct += (predicted == labels).sum().item()
  val_loss /= len(val_loader)
  val_accuracy = 100 * correct / total
  return val_loss, val_accuracy

def train_model(optim_name, model, train_loader, val_loader, loss_func, num_epochs=10):
    if optim_name == 'SGD':
        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
    elif optim_name == 'Adam':
        optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))
    elif optim_name == 'RAdam':
        optimizer = optim.RAdam(model.parameters(), lr=0.001, betas=(0.9, 0.999))
    else:
        raise ValueError(f'Unsupported optimizer: {optim_name}')

    train_losses = []
    val_losses = []
    val_accuracies = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            labels = labels.float().unsqueeze(1)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = loss_func(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        train_loss = running_loss / len(train_loader)
        train_losses.append(train_loss)

        val_loss, val_accuracy = validate_model(model, val_loader, loss_func)
        val_losses.append(val_loss)
        val_accuracies.append(val_accuracy)

        print(f'[{optim_name}] Epoch {epoch + 1}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}, Val Accuracy: {val_accuracy:.2f}%')

    return train_losses, val_losses, val_accuracies

train_losses_Adam, val_losses_Adam, val_accuracies_Adam = train_model(
    'Adam', model, train_loader, val_loader, loss_func
)

def load_and_transform_image(image_path, transform):
    image = Image.open(image_path).convert('RGB')
    return transform(image).unsqueeze(0).to(device)

class_folders = {
    'santa': f'{data_root}/test/santa',
    'normal': f'{data_root}/test/normal'
}

plt.figure(figsize=(20, 8))

counter = 1

for class_name, folder_path in class_folders.items():
    image_paths = glob.glob(os.path.join(folder_path, "*"))
    selected_paths = image_paths[:5]

    for image_path in selected_paths:
        image = load_and_transform_image(image_path, transform)

        model.eval()
        with torch.no_grad():
          outputs = model(image)
          probs = torch.sigmoid(outputs).item()
          prediction = 'santa' if probs > 0.5 else 'normal'

        plt.subplot(2, 5, counter)
        plt.imshow(Image.open(image_path))
        plt.title(f'True: {class_name}, Pred: {prediction}')
        plt.axis('off')

        counter += 1

plt.tight_layout()
plt.show()

