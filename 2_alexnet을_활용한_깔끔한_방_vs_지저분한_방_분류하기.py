# -*- coding: utf-8 -*-
"""2. AlexNet을 활용한 깔끔한 방 vs 지저분한 방 분류하기.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r2psxlAEC8hjxVQptGnWiNi_iMfe6etK
"""

import os
import glob
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.models as models
from torch.utils.data import DataLoader, Dataset
from torchvision.datasets import ImageFolder
from PIL import Image

data_root = '/content/drive/MyDrive/컴퓨터비전_시즌2/5. 컴퓨터 비전/Data/2'

def display_images(image_paths, title, max_images=4):
  plt.figure(figsize=(12, 3))
  for i, image_path in enumerate(image_paths[:max_images]):
    img = plt.imread(image_path)
    plt.subplot(1, max_images, i+1)
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')
  plt.show()

categories = ['Train Clean', 'Train Messy', 'Val Clean', 'Val Messy', 'Test Clean', 'Test Messy']

for category in categories:
  image_paths = glob.glob(f'{data_root}/{category.lower().replace(" ", "/")}/*')
  # print(image_paths)
  display_images(image_paths, category)
  print(f'{category} 총 이미지 수: {len(image_paths)}')

plt.figure(figsize=(10, 6))
plt.bar(categories, [len(glob.glob(f'{data_root}/{category.lower().replace(" ", "/")}/*')) for category in categories], color=['blue', 'orange', 'green', 'red'])
plt.title('Number of Images per Category')
plt.xlabel('Category')
plt.ylabel('NUmber of Images')
plt.xticks(rotation=45)
plt.show()

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 평균, 표준편차 0.5
])

train_dataset = ImageFolder(f'{data_root}/train', transform=transform)
val_dataset = ImageFolder(f'{data_root}/val', transform=transform)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)

"""### Alexnet

<img src='https://cdn.datamaker.io/datamaker-erp/media/uploads/2020/09/16/deepnetvis_small.png'>

* 2012년 이미지 인식 경진대회(ILSVRC, ImageNet Large Scale Visual Recognition Challenge)에서 큰 성과를 거두며 컴퓨터 비전 분야에 혁신을 가져온 CNN 모델
* 224 * 224 * 3 크기의 컬러 이미지를 입력
* 이미지에서 특징을 추출하는 역할인 5개의 컨벌루션 레이어를 사용
* Max-Pooling 레이어를 통해 공간 크기를 줄이면서 가장 중요한 정보를 유지
* ReLU 함수를 활성화 함수로 사용하여 합습 속도를 크게 향상
* 드롭아웃 기법을 사용하여 오버피팅을 방지
* 마지막 두 레이어는 4096개의 파라미터를 가지고 있으며, 마지막 레이어는 1000개의 클래스로 분류
"""

model = models.alexnet(pretrained=True)
model

for param in model.parameters():
  param.requires_grad = False

model.classifier[6] = nn.Linear(4096, 2)
# 나머지는 얼리고 5, 6만 학습하기
model.classifier[5].reguires_grad = True
model.classifier[6].reguires_grad = True

loss_func = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)

def calculate_accuracy(loader, model):
  model.eval() # 학습모드 -> 검증모드
  correct = 0
  total = 0
  with torch.no_grad():
    for data in loader:
      images, labels = data
      outputs = model(images)
      _, predicted = torch.max(outputs.data, 1)
      total += labels.size(0)
      correct += (predicted == labels).sum().item() # 맞으면 0 틀리면 1
  return 100 * correct / total

train_losses = []
val_losses = []
val_accuracies = []

num_epochs = 5
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for i, data in enumerate(train_loader):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = loss_func(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    train_loss = running_loss / len(train_loader)
    train_losses.append(train_loss)
    val_loss = 0.0
    model.eval()
    with torch.no_grad():
        for inputs, labels in val_loader:
            outputs = model(inputs)
            loss = loss_func(outputs, labels)
            val_loss += loss.item()
    val_loss /= len(val_loader)
    val_losses.append(val_loss)
    val_accuracy = calculate_accuracy(val_loader, model)
    val_accuracies.append(val_accuracy)
    print(f'Epoch {epoch + 1}, Train Loss: {train_loss: .6f}, Val Loss: {val_loss: .6f}, Val Accuracy: {val_accuracy: .2f}%')

plt.figure(figsize=(15, 5))
# 학습 손실 그래프
plt.subplot(1, 3, 1)
plt.plot(train_losses, label='Train Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.legend()
# 검증 정확도 그래프
plt.subplot(1, 3, 2)
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Validation Loss Over Epochs')
plt.legend()
# 검증 정확도 그래프
plt.subplot(1, 3, 3)
plt.plot(val_accuracies, label='Validation Accuracy', color='orange')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Validation Accuracy Over Epochs')
plt.legend()
plt.tight_layout()
plt.show()

def load_and_transform_image(image_path, transform):
  image = Image.open(image_path).convert('RGB')
  return transform(image).unsqueeze(0)

class_folders = {
    'clean': f'{data_root}/test/clean',
    'messy': f'{data_root}/test/messy'
}

plt.figure(figsize=(20, 8))
counter = 1
for class_name, folder_path in class_folders.items():
  image_paths = glob.glob(os.path.join(folder_path, "*"))
  selected_paths = image_paths[:5]
  for image_path in selected_paths:
    image = load_and_transform_image(image_path, transform)
    model.eval()
    with torch.no_grad():
      outputs = model(image)
      _, predicted = torch.max(outputs, 1)
      prediction = 'clean' if predicted.item() == 0 else 'messy'
      plt.subplot(2, 5, counter)
      plt.imshow(Image.open(image_path))
      plt.title(f'True: {class_name}, Pred: {prediction}')
      plt.axis('off')
      counter += 1
plt.tight_layout()
plt.show()

