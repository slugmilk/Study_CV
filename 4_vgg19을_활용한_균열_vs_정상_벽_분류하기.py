# -*- coding: utf-8 -*-
"""4. VGG19을 활용한 균열 vs 정상 벽 분류하기.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zqH_FAvbWeq8p8bAN5dI5WqZPv6aneRp
"""

import os
import glob
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.models as models
import numpy as np
from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler
from torchvision.datasets import ImageFolder
from PIL import Image

data_root = '/content/drive/MyDrive/컴퓨터비전 시즌2/5. 컴퓨터 비전/Data/4'

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

def display_images(image_paths, title, max_images=4):
    plt.figure(figsize=(12, 3))
    for i, image_path in enumerate(image_paths[:max_images]):
        img = plt.imread(image_path)
        plt.subplot(1, max_images, i+1)
        plt.imshow(img)
        plt.title(title)
        plt.axis('off')
    plt.show()

categories = ['Train crack', 'Train normal', 'Val crack', 'Val normal', 'Test crack', 'Test normal']

for category in categories:
    image_paths = glob.glob(f'{data_root}/{category.lower().replace(" ", "/")}/*')
    # print(image_paths)
    display_images(image_paths, category)
    print(f'{category} 총 이미지 수: {len(image_paths)}')

plt.figure(figsize=(10, 6))
plt.bar(categories, [len(glob.glob(f'{data_root}/{category.lower().replace(" ", "/")}/*')) for category in categories], color=['blue', 'orange', 'green', 'red'])
plt.title('Number of Images per Category')
plt.xlabel('Category')
plt.ylabel('Number of Images')
plt.xticks(rotation=45)
plt.show()

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

train_dataset = ImageFolder(f'{data_root}/train', transform=transform)
val_dataset = ImageFolder(f'{data_root}/val', transform=transform)

num_of_train = 34550
num_of_val = 3300
train_indices = list(range(num_of_train))
val_indices = list(range(num_of_val))

# 학습데이터 수가 많아 무작위 샘플 200개 선택
np.random.shuffle(train_indices)
train_subset_indices = train_indices[:200]

np.random.shuffle(val_indices)
val_subset_indices = val_indices[:20]

train_loader = DataLoader(dataset=train_dataset, batch_size=8, sampler=train_subset_indices)
val_loader = DataLoader(dataset=val_dataset, batch_size=8, sampler=val_subset_indices)

model = models.vgg19(pretrained=True)
model = model.to(device)
model

"""### vgg19(Visual Geometry Group 19)
* 2014년 옥스포드 대학교 연구팀이 개발한 모델 중 하나로, 대회에서 높은 성능을 보여주며 유명
* 주로 이미지 분류, 물체 검출, 이미지 특징 추출 등의 작업에 사용
* 19개의 층을 가지고 있어서 VGG19라고 부르며, 구조는 간단하지만 깊이가 깊어 이미지 분류 작업에서 우수한 성능을 발휘
* 총 16개의 컨볼루션 층이 있으며, 모든 컨볼루션 필터의 크기는 3*3
* 마지막에는 세 개의 FC 레이어가 있고, softmax 함수로 연결되어 1000개의 클래스를 예측

<img src='https://miro.medium.com/v2/resize:fit:1192/1*Q_bg1E3trWcjdk9_jnVGwg.png'>
"""

for param in model.parameters():
    param.requires_grad = False

model.classifier[6] = nn.Linear(4096, 2)
model.classifier[6].requires_grad = True
model.classifier[6] = model.classifier[6].to(device)

loss_func = nn.CrossEntropyLoss()

"""### Adam vs RAdam
* Adam
    * 학습률이 각 파라미터에 대해 다르게 조정
    * 각 파라미터의 변화량을 바탕으로 학습률을 조정하기 때문에 빠르게 수렴할 수 있음
    * 첫 번째 모멘텀 추정치(평균)와 두 번째 모멘텀 추정치(분산)을 사용
    * 해당 추정치는 파라미터의 업데이트 방향과 크기를 조정
* RAdam
    * Adam의 변형 버전
    * Adam의 장점을 유지하면서 학습 초기에 안정성을 높이기 위해 개선
    * 초기 학습률을 조정하는 방식에서 Adam의 바이어스 보정 단계를 수정하여 학습 초기 단계의 안정성을 높임(초기 학습률을 빠르게 조정하는 문제를 완화)
    * 학습 초기에 학습률을 낮추고 일정 시점 이후에는 Adam과 비슷하게 학습률을 조정
"""

def train_model(optim_name, model, train_loader, val_loader, loss_func, num_epochs=20):
    if optim_name == 'SGD':
        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
    elif optim_name == 'Adam':
        optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))
    elif optim_name == 'RAdam':
        optimizer = optim.RAdam(model.parameters(), lr=0.001, betas=(0.9, 0.999))
    else:
        raise ValueError(f'Unsupported optimizer: {optim_name}')

    train_losses = []
    val_losses = []
    val_accuracies = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for i, data in enumerate(train_loader):
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = loss_func(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        train_loss = running_loss / len(train_loader)
        train_losses.append(train_loss)

        val_loss = 0.0
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                loss = loss_func(outputs, labels)
                val_loss += loss.item()

        val_loss /= len(val_loader)
        val_losses.append(val_loss)

        val_accuracy = 100 * correct / total
        val_accuracies.append(val_accuracy)

        print(f'[{optim_name}] Epoch {epoch + 1}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}, Val Accuracy: {val_accuracy:.2f}%')

    return train_losses, val_losses, val_accuracies

train_losses_SGD, val_losses_SGD, val_accuracies_SGD = train_model(
    'SGD', model, train_loader, val_loader, loss_func
)

# 초기화
model = models.vgg19(pretrained=True)
model = model.to(device)

for param in model.parameters():
    param.requires_grad = False

model.classifier[6] = nn.Linear(4096, 2)
model.classifier[6].requires_grad = True
model.classifier[6] = model.classifier[6].to(device)

train_losses_Adam, val_losses_Adam, val_accuracies_Adam = train_model(
    'Adam', model, train_loader, val_loader, loss_func
)

# 초기화
model = models.vgg19(pretrained=True)
model = model.to(device)

for param in model.parameters():
    param.requires_grad = False

model.classifier[6] = nn.Linear(4096, 2)
model.classifier[6].requires_grad = True
model.classifier[6] = model.classifier[6].to(device)

train_losses_RAdam, val_losses_RAdam, val_accuracies_RAdam = train_model(
    'RAdam', model, train_loader, val_loader, loss_func
)

# 학습 손실과 검증 정확도 그래프 그리기
plt.figure(figsize=(15, 10))

# 학습 손실 그래프
plt.subplot(3, 1, 1)  # 3행 1열의 첫 번째 위치
plt.plot(train_losses_SGD, label='SGD')
plt.plot(train_losses_Adam, label='Adam')
plt.plot(train_losses_RAdam, label='RAdam')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.legend()

# 검증 손실 그래프
plt.subplot(3, 1, 2)  # 3행 1열의 두 번째 위치
plt.plot(val_losses_SGD, label='SGD')
plt.plot(val_losses_Adam, label='Adam')
plt.plot(val_losses_RAdam, label='RAdam')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Validation Loss Over Epochs')
plt.legend()

# 검증 정확도 그래프
plt.subplot(3, 1, 3)  # 3행 1열의 세 번째 위치
plt.plot(val_accuracies_SGD, label='SGD', color='blue')
plt.plot(val_accuracies_Adam, label='Adam', color='green')
plt.plot(val_accuracies_RAdam, label='RAdam', color='orange')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Validation Accuracy Over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

def load_and_transform_image(image_path, transform):
    image = Image.open(image_path).convert('RGB')
    return transform(image).unsqueeze(0)

class_folders = {
    'crack': f'{data_root}/test/crack',
    'normal': f'{data_root}/test/normal'
}

plt.figure(figsize=(20, 8))

counter = 1

for class_name, folder_path in class_folders.items():
    image_paths = glob.glob(os.path.join(folder_path, "*"))
    selected_paths = image_paths[:5]

    for image_path in selected_paths:
        image = load_and_transform_image(image_path, transform)
        image = image.to(device)

        model.eval()
        with torch.no_grad():
            outputs = model(image)
            _, predicted = torch.max(outputs, 1)
        prediction = 'crack' if predicted.item() == 0 else 'normal'

        plt.subplot(2, 5, counter)
        plt.imshow(Image.open(image_path))
        plt.title(f'True: {class_name}, Pred: {prediction}')
        plt.axis('off')

        counter += 1

plt.tight_layout()
plt.show()

